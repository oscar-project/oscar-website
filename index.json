[{"authors":null,"categories":null,"content":"The Common Crawl Foundation is a California 501(c)(3) registered non-profit founded by Gil Elbaz with the goal of democratizing access to web information by producing and maintaining an open repository of web crawl data that is universally accessible and analyzable.\nOur vision is of a truly open web that allows open access to information and enables greater innovation in research, business and education. We level the playing field by making wholesale extraction, transformation and analysis of web data cheap and easy.\n","date":-62135596800,"expirydate":-62135596800,"kind":"term","lang":"en","lastmod":1673983977,"objectID":"d5a4d5cf3528a10ae746864ca3bea4c0","permalink":"https://oscar-project.org/authors/partner-commoncrawl/","publishdate":"0001-01-01T00:00:00Z","relpermalink":"/authors/partner-commoncrawl/","section":"authors","summary":"The Common Crawl Foundation is a California 501(c)(3) registered non-profit founded by Gil Elbaz with the goal of democratizing access to web information by producing and maintaining an open repository of web crawl data that is universally accessible and analyzable.","tags":null,"title":"Common Crawl","type":"authors"},{"authors":null,"categories":null,"content":"Inria is the French national research institute for digital science and technology. World-class research, technological innovation and entrepreneurial risk are its DNA. In 215 project teams, most of which are shared with major research universities, more than 3,900 researchers and engineers explore new paths, often in an interdisciplinary manner and in collaboration with industrial partners to meet ambitious challenges.\nAs a technological institute, Inria supports the diversity of innovation pathways: from open source software publishing to the creation of technological startups (Deeptech).\n","date":-62135596800,"expirydate":-62135596800,"kind":"term","lang":"en","lastmod":1673983977,"objectID":"8518b4f20b66c03c11ec59df57babdf7","permalink":"https://oscar-project.org/authors/fund-inria/","publishdate":"0001-01-01T00:00:00Z","relpermalink":"/authors/fund-inria/","section":"authors","summary":"Inria is the French national research institute for digital science and technology. World-class research, technological innovation and entrepreneurial risk are its DNA. In 215 project teams, most of which are shared with major research universities, more than 3,900 researchers and engineers explore new paths, often in an interdisciplinary manner and in collaboration with industrial partners to meet ambitious challenges.","tags":null,"title":"Inria","type":"authors"},{"authors":null,"categories":null,"content":"I‚Äôm a researcher at the Speech and Language Technology Team at DFKI GmbH Berlin.\nI am interested in large corpora for training language models, specially for under resourced languages and historical languages. I am interested in tasks such as Name Entity Recognition (NER), Dependency Parsing and Part-of-Speech tagging, Machine Translation and Document structuration.\nI love coffee, cookies and maths. ‚òïüç™\n","date":-62135596800,"expirydate":-62135596800,"kind":"term","lang":"en","lastmod":1677087533,"objectID":"d0afc1aafe936456114b5d845db0a44a","permalink":"https://oscar-project.org/authors/pedro/","publishdate":"0001-01-01T00:00:00Z","relpermalink":"/authors/pedro/","section":"authors","summary":"I‚Äôm a researcher at the Speech and Language Technology Team at DFKI GmbH Berlin.\nI am interested in large corpora for training language models, specially for under resourced languages and historical languages.","tags":null,"title":"Pedro Ortiz Suarez","type":"authors"},{"authors":null,"categories":null,"content":"Sebastian is a programmer and computational linguist living in the south of Germany. He is responsible for running and maintaining the crawler and will support you to use the data. Prior to joining Common Crawl, he worked as software developer at Exorbyte, implementing search and data quality solutions.\nSebastian holds a PhD in computational linguistics from University of Munich. He studied linguistics (Slavic languages) and cultural anthropology in Munich, Kazan and Prague. Sebastian is a committer of Apache Nutch and a member of the Apache Software Foundation.\n","date":-62135596800,"expirydate":-62135596800,"kind":"term","lang":"en","lastmod":1675151147,"objectID":"dc09809cd94ad5eeb0e52654d1887e9f","permalink":"https://oscar-project.org/authors/collab-sebastian/","publishdate":"0001-01-01T00:00:00Z","relpermalink":"/authors/collab-sebastian/","section":"authors","summary":"Sebastian is a programmer and computational linguist living in the south of Germany. He is responsible for running and maintaining the crawler and will support you to use the data. Prior to joining Common Crawl, he worked as software developer at Exorbyte, implementing search and data quality solutions.","tags":null,"title":"Sebastian Nagel","type":"authors"},{"authors":null,"categories":null,"content":"I am a Ph.D. student at the Data and Web Science Group at the University of Mannheim.\nMy current interest is automatic summarization systems for research papers. Additionally, to academic side of the field, I also like to develop webpages and software.\nI love coffee, reading papers and books.\n","date":-62135596800,"expirydate":-62135596800,"kind":"term","lang":"en","lastmod":1673983977,"objectID":"247912bed8bf7a4a8f6cd01564c97a4b","permalink":"https://oscar-project.org/authors/contrib-sotaro/","publishdate":"0001-01-01T00:00:00Z","relpermalink":"/authors/contrib-sotaro/","section":"authors","summary":"I am a Ph.D. student at the Data and Web Science Group at the University of Mannheim.\nMy current interest is automatic summarization systems for research papers. Additionally, to academic side of the field, I also like to develop webpages and software.","tags":null,"title":"Sotaro Takeshita","type":"authors"},{"authors":null,"categories":null,"content":"I am a PhD student at Ludwig Ludwig Maximilian University of Munich, supervised by prof Hinrich Schuetze. My research is in natural language processing and machine learning.\nMy research focus is on various aspects of multilingual models, including their cross-lingual transferability capability and their applications. I am also interested in parameter-efficient methods, and low-resource learning.\n","date":-62135596800,"expirydate":-62135596800,"kind":"term","lang":"en","lastmod":1675151147,"objectID":"75e850e9647a3e69a0aa9c25f8a6d348","permalink":"https://oscar-project.org/authors/collab-ayoob/","publishdate":"0001-01-01T00:00:00Z","relpermalink":"/authors/collab-ayoob/","section":"authors","summary":"I am a PhD student at Ludwig Ludwig Maximilian University of Munich, supervised by prof Hinrich Schuetze. My research is in natural language processing and machine learning.\nMy research focus is on various aspects of multilingual models, including their cross-lingual transferability capability and their applications.","tags":null,"title":"Ayyoob Imani","type":"authors"},{"authors":null,"categories":null,"content":"The German Research Center for Artificial Intelligence (DFKI) was founded in 1988 as a non-profit public-private partnership. It has research facilities in Kaiserslautern, Saarbr√ºcken and Bremen, Niedersachsen, laboratories in Berlin and Darmstadt, and branch offices in L√ºbeck and Trier. In the field of innovative commercial software technology using Artificial Intelligence, DFKI is the leading research center in Germany.\nBased on application oriented basic research, DFKI develops product functions, prototypes and patentable solutions in the field of information and communication technology. Research and development projects are conducted in 27 research departments, nine competence centers and eight living labs. Funding is received from government agencies like the European Union, the Federal Ministry of Education and Research (BMBF), the Federal Ministry for Economic Affairs and Climate Action (BMWK), the German Federal States and the German Research Foundation (DFG), as well as from cooperation with industrial partners. Twice a year, a committee of internationally renowned experts (Scientific Advisory Board) audits the progress and results of state-funded projects.\nApart from the state governments of Rhineland-Palatinate, Saarland and Bremen, numerous renowned German and international high-tech companies from a wide range of industrial sectors are represented on the DFKI supervisory board. The DFKI model of a non-profit public-private partnership (ppp) is nationally and internationally considered a blueprint for corporate structure in the field of top-level research.\nDFKI is actively involved in numerous organizations representing and continuously advancing Germany as an excellent location for cutting-edge research and technology. Far beyond the country‚Äôs borders DFKI enjoys an excellent reputation for its academic training of young scientists. At present, approx. 890 highly qualified researchers, administrators and 610 graduate students from more than 65 countries are contributing to more than 390 DFKI research projects. DFKI serves as a stepping stone to leading positions in industry and successful careers as founders of spin-off companies. Over the years, more than 160 staff members have been appointed professors at universities in Germany and abroad.\n","date":-62135596800,"expirydate":-62135596800,"kind":"term","lang":"en","lastmod":1673983977,"objectID":"51ddf1565c55bd16203b22b8331d2e8a","permalink":"https://oscar-project.org/authors/fund-dfki/","publishdate":"0001-01-01T00:00:00Z","relpermalink":"/authors/fund-dfki/","section":"authors","summary":"The German Research Center for Artificial Intelligence (DFKI) was founded in 1988 as a non-profit public-private partnership. It has research facilities in Kaiserslautern, Saarbr√ºcken and Bremen, Niedersachsen, laboratories in Berlin and Darmstadt, and branch offices in L√ºbeck and Trier.","tags":null,"title":"DFKI","type":"authors"},{"authors":null,"categories":null,"content":"The Data and Web Science Group at the University of Mannheim conducts research and offer teaching in the areas data analytics, artificial intelligence, natural language processing, and data integration. The group consists of 7 professors and around 35 researchers and supporting staff members.\n","date":-62135596800,"expirydate":-62135596800,"kind":"term","lang":"en","lastmod":1673985368,"objectID":"1972108b2c8b391e06104c9f0dc4e4ce","permalink":"https://oscar-project.org/authors/partner-uni-mannheim/","publishdate":"0001-01-01T00:00:00Z","relpermalink":"/authors/partner-uni-mannheim/","section":"authors","summary":"The Data and Web Science Group at the University of Mannheim conducts research and offer teaching in the areas data analytics, artificial intelligence, natural language processing, and data integration. The group consists of 7 professors and around 35 researchers and supporting staff members.","tags":null,"title":"DWS at the University of Mannheim","type":"authors"},{"authors":null,"categories":null,"content":"I‚Äôm a research engineer working on better software to generate, manage and filter large corpora. I use Rust and Python to improve performance and safety of code and generate statistical data about generated corpora.\nI‚Äôm interested in bringing more software engineering practices in research software in order to improve performance and reliability. I am currently employed at the ALMAnaCH research team at Inria.\nI like movies, making music and eating falafel üßÜ.\n","date":-62135596800,"expirydate":-62135596800,"kind":"term","lang":"en","lastmod":1670526880,"objectID":"d0f9b85571ca19bff50c8d5ae6303df4","permalink":"https://oscar-project.org/authors/julien/","publishdate":"0001-01-01T00:00:00Z","relpermalink":"/authors/julien/","section":"authors","summary":"I‚Äôm a research engineer working on better software to generate, manage and filter large corpora. I use Rust and Python to improve performance and safety of code and generate statistical data about generated corpora.","tags":null,"title":"Julien Abadji","type":"authors"},{"authors":null,"categories":null,"content":"I am a Data Scientist at H\u0026amp;M Group in Stockholm, working in the AI Research team.\nMy current research interests are generative models, especially normalizing flows, and language models.\nI strive to make self-developed AI models usable by everyone through simple APIs and standardized processes.\n","date":-62135596800,"expirydate":-62135596800,"kind":"term","lang":"en","lastmod":1673983977,"objectID":"3340105e5e3dc183a801b6fa2ade3e7e","permalink":"https://oscar-project.org/authors/contrib-patrick/","publishdate":"0001-01-01T00:00:00Z","relpermalink":"/authors/contrib-patrick/","section":"authors","summary":"I am a Data Scientist at H\u0026M Group in Stockholm, working in the AI Research team.\nMy current research interests are generative models, especially normalizing flows, and language models.\nI strive to make self-developed AI models usable by everyone through simple APIs and standardized processes.","tags":null,"title":"Patrick Teufert","type":"authors"},{"authors":null,"categories":null,"content":"ALMAnaCH project-team Inria Paris‚Äô NLP research team Research in Artificial Intelligence bringing together Natural Language Processing and Computational Humanities.\n","date":-62135596800,"expirydate":-62135596800,"kind":"term","lang":"en","lastmod":1673983977,"objectID":"a4b65157f496d2265db00f5ff7e0ac43","permalink":"https://oscar-project.org/authors/fund-almanach/","publishdate":"0001-01-01T00:00:00Z","relpermalink":"/authors/fund-almanach/","section":"authors","summary":"ALMAnaCH project-team Inria Paris‚Äô NLP research team Research in Artificial Intelligence bringing together Natural Language Processing and Computational Humanities.","tags":null,"title":"ALMAnaCH","type":"authors"},{"authors":null,"categories":null,"content":"The Ludwig Maximilian University of Munich is a public research university in Munich, Germany. It is Germany‚Äôs sixth-oldest university in continuous operation.\n","date":-62135596800,"expirydate":-62135596800,"kind":"term","lang":"en","lastmod":1675151147,"objectID":"453779fd8be9722c1654d24086d71d2c","permalink":"https://oscar-project.org/authors/partner-lmu/","publishdate":"0001-01-01T00:00:00Z","relpermalink":"/authors/partner-lmu/","section":"authors","summary":"The Ludwig Maximilian University of Munich is a public research university in Munich, Germany. It is Germany‚Äôs sixth-oldest university in continuous operation.","tags":null,"title":"Ludwig-Maximilians-Universit√§t M√ºnchen","type":"authors"},{"authors":null,"categories":null,"content":"I am a Research Engineer at ALMAnaCH Inria team, I am interested in natural language processing for low resources languages and dialects. I have a MSc in Machine Learning and B.Sc in Statistics and Computer Science.\n","date":-62135596800,"expirydate":-62135596800,"kind":"term","lang":"en","lastmod":1670526880,"objectID":"1ba0c8fbaa2d32ebec8bc48fb455f6db","permalink":"https://oscar-project.org/authors/rua/","publishdate":"0001-01-01T00:00:00Z","relpermalink":"/authors/rua/","section":"authors","summary":"I am a Research Engineer at ALMAnaCH Inria team, I am interested in natural language processing for low resources languages and dialects. I have a MSc in Machine Learning and B.","tags":null,"title":"Rua Ismail","type":"authors"},{"authors":null,"categories":null,"content":"Laurent Romary is Directeur de Recherche at Inria, France and director general of DARIAH. He received a PhD degree in computational linguistics in 1989 and his Habilitation in 1999. He carries out research on the modelling of semi-structured documents, with a specific emphasis on texts and linguistic resources. He has been active in standardisation activities with ISO, as chair of committee ISO/TC 37/SC 4 (2002-2014), chair of ISO/TC 37 (2016-) and the Text Encoding Initiative, as member (2001-2011) and chair (2008-2011) of its technical council. He has been involved in the definition of the scientific information policy of CNRS (2005-2006), the Max-Planck Digital Library (2006-2008) and Inria (2006-).\n","date":-62135596800,"expirydate":-62135596800,"kind":"term","lang":"en","lastmod":1674037332,"objectID":"5aa5bdf7fb31aded56ed5ea9447af54c","permalink":"https://oscar-project.org/authors/laurent/","publishdate":"0001-01-01T00:00:00Z","relpermalink":"/authors/laurent/","section":"authors","summary":"Laurent Romary is Directeur de Recherche at Inria, France and director general of DARIAH. He received a PhD degree in computational linguistics in 1989 and his Habilitation in 1999. He carries out research on the modelling of semi-structured documents, with a specific emphasis on texts and linguistic resources.","tags":null,"title":"Laurent Romary","type":"authors"},{"authors":null,"categories":null,"content":"The Prairie Institute (PaRis AI Research InstitutE) is one of the four French Institutes of Artificial Intelligence, which were created as part of the national French initiative on AI announced by President Emmanuel Macron on May 29, 2018.\nA major part of this ambitious plan, which has a total budget of one billion euros, was the creation of a small number of interdisciplinary AI research institutes (or ‚Äú3IAs‚Äù for ‚ÄúInstituts Interdisciplinaires d‚ÄôIntelligence Artificielle‚Äù). After an open call for participation in July 2018 and two rounds of review by an international scientific committee, the Grenoble, Nice, Paris and Toulouse projects have officially received the 3IA label on April 24, 2019, with a total budget of 75 million Euros.\n","date":-62135596800,"expirydate":-62135596800,"kind":"term","lang":"en","lastmod":1673983977,"objectID":"9ef9b15044520a089267f46acab1f74c","permalink":"https://oscar-project.org/authors/fund-prarie/","publishdate":"0001-01-01T00:00:00Z","relpermalink":"/authors/fund-prarie/","section":"authors","summary":"The Prairie Institute (PaRis AI Research InstitutE) is one of the four French Institutes of Artificial Intelligence, which were created as part of the national French initiative on AI announced by President Emmanuel Macron on May 29, 2018.","tags":null,"title":"Prairie Institute","type":"authors"},{"authors":null,"categories":null,"content":"Inria Senior Researcher in Natural Language Processing and Computational Linguistics. Head of the ALMAnaCH research team. PRAIRIE chair.\n","date":-62135596800,"expirydate":-62135596800,"kind":"term","lang":"en","lastmod":1674037332,"objectID":"2d1d85691b221638c9407df7e99b0a55","permalink":"https://oscar-project.org/authors/benoit/","publishdate":"0001-01-01T00:00:00Z","relpermalink":"/authors/benoit/","section":"authors","summary":"Inria Senior Researcher in Natural Language Processing and Computational Linguistics. Head of the ALMAnaCH research team. PRAIRIE chair.","tags":null,"title":"Beno√Æt Sagot","type":"authors"},{"authors":null,"categories":null,"content":"Large-scale language models are a key AI technology. They can recognize, produce, translate and process speech at a level hardly distinguishable from that of a human being.\nThe economic potential of large AI language models is enormous. As yet, the most successful AI language models come from the USA and China. These are often not fully available to the free market and applicable to the English and Chinese languages only. The rapidly growing importance of large-scale AI language models calls for the urgent need to ensure technology and data independence as well as innovation and competitiveness for Europe.\nOpenGPT-X builds and trains large-scale AI language models to drive innovative language application services for the European economy. Through the open Gaia-X infrastructure, businesses will be able to use and share data and services free of charge, in multiple languages and according to the highest European data protection standards to develop products and processes with a wide variety of language features (e.g. chatbots, digital assistants and personalised media reports). The collaborative project between science, business and technology is funded by the German Federal Ministry of Economics and Climate Protection (BMWK) from January 2022 to December 2024 as part of the funding program Innovative and Practical Applications and Data Spaces in the Gaia-X Digital Ecosystem.\n","date":-62135596800,"expirydate":-62135596800,"kind":"term","lang":"en","lastmod":1673983977,"objectID":"b0157c0505963b369b247e47ec565edd","permalink":"https://oscar-project.org/authors/fund-opengpt-x/","publishdate":"0001-01-01T00:00:00Z","relpermalink":"/authors/fund-opengpt-x/","section":"authors","summary":"Large-scale language models are a key AI technology. They can recognize, produce, translate and process speech at a level hardly distinguishable from that of a human being.\nThe economic potential of large AI language models is enormous.","tags":null,"title":"OpenGPT-X","type":"authors"},{"authors":null,"categories":null,"content":"The OSCAR project (Open Super-large Crawled Aggregated coRpus) is an Open Source project aiming to provide web-based multilingual resources and datasets for Machine Learning (ML) and Artificial Intelligence (AI) applications. The project focuses specifically in providing large quantities of unannotated raw data that is commonly used in the pre-training of large deep learning models. The OSCAR project has developed high-performance data pipelines specifically conceived to classify and filter large amounts of web data. The project has also put special attention in improving the data quality of web-based corpora as well as providing data for low-resource languages, so that these new ML/AI technologies are accessible to as many communities as possible.\nThe new OSCAR 23.01 is finally available, check it out here! üöÄ Join our Discord community here! üí¨ Data is distributed by language in both original and deduplicated form. There are currently 166 different languages available. If you use OSCAR please consider giving us some feedback by writing to our mail address down below. Also consider citing our papers.\nIf you want to contribute to OSCAR, please open a pull request here.\nSince 2019, The OSCAR Project has been funded by Inria (project-team ALMAnaCH) and the PRAIRIE institute. Starting in 2023, DFKI and the German Federal Ministry for Economic Affairs and Climate Action (BMWK) through the project OpenGPT-X, have joined Inria, ALMAnaCH and the PRAIRIE institute in providing funding for the OSCAR Project. During 2022 and at the beginning of 2023, OSCAR was also shortly funded by The University of Mannheim.\nIf you are interested in OSCAR and would like to access the corpus, send us a mail using the mail address down below, with ‚ÄúOSCAR Access Request‚Äù as mail title. Please include your name, last name, affiliation, contact details, which languages do you need and a brief description of how you intend to use OSCAR.\n","date":-62135596800,"expirydate":-62135596800,"kind":"term","lang":"en","lastmod":1677087533,"objectID":"2525497d367e79493fd32b198b28f040","permalink":"https://oscar-project.org/authors/admin/","publishdate":"0001-01-01T00:00:00Z","relpermalink":"/authors/admin/","section":"authors","summary":"The OSCAR project (Open Super-large Crawled Aggregated coRpus) is an Open Source project aiming to provide web-based multilingual resources and datasets for Machine Learning (ML) and Artificial Intelligence (AI) applications. The project focuses specifically in providing large quantities of unannotated raw data that is commonly used in the pre-training of large deep learning models.","tags":null,"title":"OSCAR","type":"authors"},{"authors":["Julien Abadji","Pedro Ortiz Suarez"],"categories":["news"],"content":" The new OSCAR 23.01 is finally available, check it out here! üöÄ After one year of work, we‚Äôre happy to announce the release of OSCAR 23.01! üöÄ OSCAR 23.01 is the January 2023 version of the OSCAR Corpus based on the November/December 2022 dump of Common Crawl. While being quite similar to OSCAR 22.01, it contains several new features, including:\nKenLM-based adult content detection üëÄ Precomputed Locality-Sensitive Hashes for near deduplication üìç Blocklist-based categories üìö Zstandard compression üì¶ A new blocklist specifically made for Japanese üáØüáµ Language naming changes to better respect the BCP47 standard ‚úèÔ∏èü§ì To get access to this version and more information about it, please visit our documentation here.\n","date":1677070931,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1677087533,"objectID":"c32a3bb5b3c3cc9c4747c7b017a31737","permalink":"https://oscar-project.org/post/news-23-01/","publishdate":"2023-02-22T15:02:11+02:00","relpermalink":"/post/news-23-01/","section":"post","summary":"New filters, new categories, more compression, a fresh corpus and more","tags":[],"title":"News: OSCAR 23.01 Release","type":"post"},{"authors":["Julien Abadji","Pedro Ortiz Suarez","Laurent Romary","Beno√Æt Sagot"],"categories":null,"content":"","date":1642457579,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1647269568,"objectID":"40179a8d702c46ef8f54483a0a9bafa8","permalink":"https://oscar-project.org/publication/2022/arxiv/towards/","publishdate":"2017-01-01T00:00:00Z","relpermalink":"/publication/2022/arxiv/towards/","section":"publication","summary":"we take the existing multilingual web corpus OSCAR and its pipeline Ungoliant that extracts and classifies data from Common Crawl at the line level, and propose a set of improvements and automatic annotations in order to produce a new document-oriented version of OSCAR.","tags":null,"title":"Towards a Cleaner Document-Oriented Multilingual Crawled Corpus","type":"publication"},{"authors":null,"categories":null,"content":" Table of Contents How can I get the original files using the HuggingFace datasets platform? How can I decompress OSCAR Corpus files? Having a question or an issue with OSCAR? How can I get the original files using the HuggingFace datasets platform? HuggingFace‚Äôs datasets library internally uses Apache arrow files, different from the txt.gz/jsonl.gz pair that we use. These .arrow files can usually be found in ~/.cache/huggingface/datasets/ subfolders.\nHowever, it is possible to get the original (txt.gz/jsonl.gz) files using Git LFS.\nThe following steps assume you have git and git-lfs installed, and are on a UNIX system. The procedure should roughly be the same on Windows, but hasn‚Äôt been attempted.\n$\u0026gt; GIT_LFS_SKIP_SMUDGE=1 git clone https://huggingface.co/datasets/oscar-corpus/OSCAR-2109 # clone the repository, ignoring LFS files $\u0026gt; cd OSCAR-2109 # go inside the directory $\u0026gt; git lfs pull --include packaged/eu/eu.txt.gz # pull the required file(s) (here the Basque corpus). Check with the manpage for pull options You‚Äôre all set! Decompress the files and you are ready to use the corpus.\nHow can I decompress OSCAR Corpus files? OSCAR is distributed in split files that are compressed in order to save spave. However, some decompression programs have trouble dealing with gz files. Here are some programs that work well for the three mainstream operating systems:\nOSX/Linux-based: Use gzip -d FILE.gz. Windows: Use 7zip Having a question or an issue with OSCAR? Send us your question by mail using the mail address in our homepage\n","date":1630658036,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1639068424,"objectID":"4a1318da06786ac52626178ca960109e","permalink":"https://oscar-project.org/faq/","publishdate":"2021-09-03T10:33:56+02:00","relpermalink":"/faq/","section":"","summary":"Table of Contents How can I get the original files using the HuggingFace datasets platform? How can I decompress OSCAR Corpus files? Having a question or an issue with OSCAR?","tags":null,"title":"Frequently Asked Questions","type":"page"},{"authors":["Julien Abadji","Pedro Ortiz Suarez"],"categories":["news"],"content":"September 2021 marks an important milestone regarding OSCAR, and we have important news to share.\nNew pipeline tool The previous OSCAR corpus was generated by goclassy.\nThe latest (at the time of writing) and future ones will be generated by Ungoliant, a brand new corpus generation tool written in Rust.\nThe tool provides a more accessible Command Line Interface, with the following features:\nDowloading of CommonCrawl shards from a wet.paths file, Generation of a corpus from CommonCrawl shards, Deduplication, Splitting in files of fixed maxiumum size, Packaging (GZipping + checksum file creation) It is also possible (but not yet used/tested in terms of ergonomics) to use Ungoliant as a library.\nNew schema OSCAR is changing and will change again on the course of the following months/years, and as such it is important to provide a way to announce and specify schema changes.\nThe new OSCAR Corpus release follows the OSCAR Schema v1.1, enabling users to optionally get metadata extracted from CommonCrawl, while retaining backward compatibility, making the update from OSCAR 2018 to OSCAR 21.09 as effortless as possible.\nIn a gist, OSCAR Schema v1.1 adds \u0026lt;lang\u0026gt;_meta.jsonl JSONLines files that holds metadata. Each line has an offset and an nb_sentences field that can be used to get related lines in text files.\nNew corpus OSCAR 21.09 is the latest release of the OSCAR Corpus. The first to be generated by Ungoliant, and also the first containing metadata.\nNote that the data used to generate the corpus is from February 2021, but the next releases of OSCAR Corpus will try to narrow the gap between source data and corpus release.\nAnother important information is that there is no shuffled version anymore.\nIt is expected to be available during September 2021 via manual application through the Contact form of the website, and later on other platforms.\n","date":1630590355,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1677087533,"objectID":"b14b90cb26f7528504366223e6832672","permalink":"https://oscar-project.org/post/news-21-09/","publishdate":"2021-09-02T15:45:55+02:00","relpermalink":"/post/news-21-09/","section":"post","summary":"New tools, metadata, and a fresh corpus.","tags":[],"title":"OSCAR News: September 2021","type":"post"},{"authors":["Julien Abadji","Pedro Ortiz Suarez","Laurent Romary","Beno√Æt Sagot"],"categories":null,"content":"","date":1626998400,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1630676828,"objectID":"6d8be031bf26602ae3c68247d44cc66b","permalink":"https://oscar-project.org/publication/2021/cmlc9/ungoliant/","publishdate":"2017-01-01T00:00:00Z","relpermalink":"/publication/2021/cmlc9/ungoliant/","section":"publication","summary":"We propose a new pipeline that is faster, modular, parameterizable, and well documented. We use it to create a corpus similar to OSCAR but larger and based on recent data.","tags":null,"title":"Ungoliant: An Optimized Pipeline for the Generation of a Very Large-Scale Multilingual Web Corpus","type":"publication"},{"authors":["Julien Abadji","Pedro Ortiz Suarez","Laurent Romary","Beno√Æt Sagot"],"categories":null,"content":"","date":1626084e3,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1630678232,"objectID":"58c1d9232e4b49bfb132a82fa88048dc","permalink":"https://oscar-project.org/talk/cmlc9/","publishdate":"2017-01-01T00:00:00Z","relpermalink":"/talk/cmlc9/","section":"talk","summary":"We propose a new pipeline that is faster, modular, parameterizable, and well documented. We use it to create a corpus similar to OSCAR but larger and based on recent data.","tags":[],"title":"Ungoliant: An Optimized Pipeline for the Generation of a Very Large-Scale Multilingual Web Corpus","type":"talk"},{"authors":["Isaac Caswell","Julia Kreutzer","Lisa Wang","Ahsan Wahab","Daan van Esch","Nasanbayar Ulzii-Orshikh","Allahsera Tapo","Nishant Subramani","Artem Sokolov","Claytone Sikasote","Monang Setyawan","Supheakmungkol Sarin","Sokhar Samb","Beno√Æt Sagot","Clara Rivera","Annette Rios","Isabel Papadimitriou","Salomey Osei","Pedro Ortiz Suarez","Iroro Orife","Kelechi Ogueji","Rubungo Andre Niyongabo","Toan Q. Nguyen","Mathias M√ºller","Andr√© M√ºller","Shamsuddeen Hassan Muhammad","Nanda Muhammad","Ayanda Mnyakeni","Jamshidbek Mirzakhalov","Tapiwanashe Matangira","Colin Leong","Nze Lawson","Sneha Kudugunta","Yacine Jernite","Mathias Jenny","Orhan Firat","Bonaventure F. P. Dossou","Sakhile Dlamini","Nisansa de Silva","Sakine √áabuk Ballƒ±","Stella Biderman","Alessia Battisti","Ahmed Baruwa","Ankur Bapna","Pallavi Baljekar","Israel Abebe Azime","Ayodele Awokoya","Duygu Ataman","Orevaoghene Ahia","Oghenefego Ahia","Sweta Agrawal","Mofetoluwa Adeyemi"],"categories":null,"content":"","date":1616371200,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1630676828,"objectID":"17643513f55a6e0896fc47473a68a064","permalink":"https://oscar-project.org/publication/2021/africanlp/quality/","publishdate":"2017-01-01T00:00:00Z","relpermalink":"/publication/2021/africanlp/quality/","section":"publication","summary":"We audit 5 multilingual corpora, finding that lower-resource corpora have systematic issues.","tags":null,"title":"Quality at a Glance: An Audit of Web-Crawled Multilingual Datasets","type":"publication"},{"authors":["Pedro Ortiz Suarez","Laurent Romary","Beno√Æt Sagot"],"categories":null,"content":"","date":1594033200,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1630678232,"objectID":"b5ca6c7c105c6b1158aea6bcd07eaa03","permalink":"https://oscar-project.org/talk/acl2020/","publishdate":"2017-01-01T00:00:00Z","relpermalink":"/talk/acl2020/","section":"talk","summary":"We explore the impact of the training corpus on contextualized word embeddings in five mid-resource languages.","tags":[],"title":"A Monolingual Approach to Contextualized Word Embeddings for Mid-Resource Languages","type":"talk"},{"authors":["Pedro Ortiz Suarez","Laurent Romary","Beno√Æt Sagot"],"categories":null,"content":"","date":1593993600,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1630676828,"objectID":"1a9e4c9337d222e180c1532ee82db482","permalink":"https://oscar-project.org/publication/2020/acl/elmos/","publishdate":"2017-01-01T00:00:00Z","relpermalink":"/publication/2020/acl/elmos/","section":"publication","summary":"We explore the impact of the training corpus on contextualized word embeddings in five mid-resource languages.","tags":null,"title":"A Monolingual Approach to Contextualized Word Embeddings for Mid-Resource Languages","type":"publication"},{"authors":["Pedro Ortiz Suarez","Yoann Dupont","Benjamin Muller","Laurent Romary","Beno√Æt Sagot"],"categories":null,"content":"","date":1589587200,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1630676828,"objectID":"123816d2a0b8bc603764d9e67953db60","permalink":"https://oscar-project.org/publication/2020/lrec/ner/","publishdate":"2017-01-01T00:00:00Z","relpermalink":"/publication/2020/lrec/ner/","section":"publication","summary":"We explore convert the NER annotations of the French TreeBank to a more user-friendly format and establish a new state of the art for French NER.","tags":null,"title":"Establishing a New State-of-the-Art for French Named Entity Recognition","type":"publication"},{"authors":["Pedro Ortiz Suarez","Beno√Æt Sagot","Laurent Romary"],"categories":null,"content":"","date":1563787800,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1630678232,"objectID":"6a3aeb492867571bc30acaa749b486aa","permalink":"https://oscar-project.org/talk/cmlc7/","publishdate":"2017-01-01T00:00:00Z","relpermalink":"/talk/cmlc7/","section":"talk","summary":"We propose a new pipeline to filter, clean and classify Common Crawl by language, we publish the final corpus under the name OSCAR.","tags":[],"title":"Asynchronous Pipeline for Processing Huge Corpora on Medium to Low Resource Infrastructures","type":"talk"},{"authors":["Pedro Ortiz Suarez","Beno√Æt Sagot","Laurent Romary"],"categories":null,"content":"","date":1563753600,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1630676828,"objectID":"25f6289c4f5df45b3b287ebb8df27a65","permalink":"https://oscar-project.org/publication/2019/clmc7/asynchronous/","publishdate":"2017-01-01T00:00:00Z","relpermalink":"/publication/2019/clmc7/asynchronous/","section":"publication","summary":"We propose a new pipeline to filter, clean and classify Common Crawl by language, we publish the final corpus under the name OSCAR.","tags":null,"title":"Asynchronous Pipeline for Processing Huge Corpora on Medium to Low Resource Infrastructures","type":"publication"}]